{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd4b29cc-073a-4a70-a003-10d334421bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3880e6a3-aec5-46d9-9872-0437a2b28495",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./runs/classification_all/')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0577456a-c917-40f5-8e72-b57a8924dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COMDataset(Dataset):\n",
    "    def __init__(self, production_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.prodiction_dir = production_dir\n",
    "        self.com_dir = os.path.join(production_dir, 'com_dir')\n",
    "        self.com_list = []\n",
    "        self.com_files = os.listdir(self.com_dir)\n",
    "        self.com_files = [f for f in os.listdir(self.com_dir) if f.endswith('.txt')]\n",
    "        self.com_files.sort(key=self.sort_coms)\n",
    "        for window, file in enumerate(self.com_files):\n",
    "            self.com_list.append(pd.read_csv(os.path.join(self.com_dir, file), header=None, names=[window], usecols=[0]))\n",
    "        self.com_list = np.array(self.com_list)\n",
    "        for idxs in range(len(self.com_list)):\n",
    "            for i in range(len(self.com_list[idxs])):\n",
    "                self.com_list[idxs][i][0] = np.float64(self.com_list[idxs][i][0][9:].strip()) \n",
    "        self.com_list = self.com_list.squeeze()\n",
    "        \n",
    "        self.n_windows = len(self.com_files)\n",
    "        self.window_paths = [os.path.join(self.prodiction_dir, str(window), 'hb_observable.txt') for window in range(self.n_windows)]\n",
    "        self.hb_list = []\n",
    "        for window, path in enumerate(self.window_paths):\n",
    "            self.hb_list.append(pd.read_csv(path, header=None,names=[window], usecols=[0]))        \n",
    "        self.hb_list = np.array(self.hb_list).squeeze()\n",
    "        \n",
    "        self.x = np.reshape(self.com_list, self.com_list.shape[0] * self.com_list.shape[1])\n",
    "        self.y = np.reshape(self.hb_list, self.hb_list.shape[0] * self.hb_list.shape[1])\n",
    "\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def sort_coms(self, file):\n",
    "        # Method to sort com files by window number\n",
    "        var = int(file.split('_')[-1].split('.')[0])\n",
    "        return var\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a77217f6-2234-4a0e-91eb-b987ef78beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_dir = '/scratch/mlsample/ipy_oxDNA/ipy_oxdna_examples/duplex_melting/us_melting/production/'\n",
    "dataset  = COMDataset(production_dir)\n",
    "batch_size = 4096\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b23a9a5c-6ee8-4a48-ac20-f6b9355d7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2c4c3d5f-1dd2-46a9-9bef-b55d1141fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "input_size = 1 # 28x28\n",
    "hidden_size = 64\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0284fa78-104e-419c-8f79-09f797fc3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6170cd7-c559-484d-8368-cbe17d603627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_753641/1036382575.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 10, step 100/ 928, loss = 2.2507\n",
      "epoch 1 / 10, step 200/ 928, loss = 1.5442\n",
      "epoch 1 / 10, step 300/ 928, loss = 1.1364\n",
      "epoch 1 / 10, step 400/ 928, loss = 0.9641\n",
      "epoch 1 / 10, step 500/ 928, loss = 0.8054\n",
      "epoch 1 / 10, step 600/ 928, loss = 0.7487\n",
      "epoch 1 / 10, step 700/ 928, loss = 0.6989\n",
      "epoch 1 / 10, step 800/ 928, loss = 0.6796\n",
      "epoch 1 / 10, step 900/ 928, loss = 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:16<02:26, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 / 10, step 100/ 928, loss = 0.5747\n",
      "epoch 2 / 10, step 200/ 928, loss = 0.5531\n",
      "epoch 2 / 10, step 300/ 928, loss = 0.5226\n",
      "epoch 2 / 10, step 400/ 928, loss = 0.5411\n",
      "epoch 2 / 10, step 500/ 928, loss = 0.5180\n",
      "epoch 2 / 10, step 600/ 928, loss = 0.4837\n",
      "epoch 2 / 10, step 700/ 928, loss = 0.5070\n",
      "epoch 2 / 10, step 800/ 928, loss = 0.4560\n",
      "epoch 2 / 10, step 900/ 928, loss = 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:29<01:55, 14.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 / 10, step 100/ 928, loss = 0.4657\n",
      "epoch 3 / 10, step 200/ 928, loss = 0.4506\n",
      "epoch 3 / 10, step 300/ 928, loss = 0.4407\n",
      "epoch 3 / 10, step 400/ 928, loss = 0.4296\n",
      "epoch 3 / 10, step 500/ 928, loss = 0.4267\n",
      "epoch 3 / 10, step 600/ 928, loss = 0.3887\n",
      "epoch 3 / 10, step 700/ 928, loss = 0.4097\n",
      "epoch 3 / 10, step 800/ 928, loss = 0.4246\n",
      "epoch 3 / 10, step 900/ 928, loss = 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:45<01:47, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 / 10, step 100/ 928, loss = 0.4144\n",
      "epoch 4 / 10, step 200/ 928, loss = 0.4028\n",
      "epoch 4 / 10, step 300/ 928, loss = 0.4212\n",
      "epoch 4 / 10, step 400/ 928, loss = 0.4116\n",
      "epoch 4 / 10, step 500/ 928, loss = 0.3853\n",
      "epoch 4 / 10, step 600/ 928, loss = 0.3745\n",
      "epoch 4 / 10, step 700/ 928, loss = 0.3909\n",
      "epoch 4 / 10, step 800/ 928, loss = 0.3794\n",
      "epoch 4 / 10, step 900/ 928, loss = 0.3990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:58<01:26, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 / 10, step 100/ 928, loss = 0.3583\n",
      "epoch 5 / 10, step 200/ 928, loss = 0.3709\n",
      "epoch 5 / 10, step 300/ 928, loss = 0.3758\n",
      "epoch 5 / 10, step 400/ 928, loss = 0.3768\n",
      "epoch 5 / 10, step 500/ 928, loss = 0.3709\n",
      "epoch 5 / 10, step 600/ 928, loss = 0.3494\n",
      "epoch 5 / 10, step 700/ 928, loss = 0.3651\n",
      "epoch 5 / 10, step 800/ 928, loss = 0.3606\n",
      "epoch 5 / 10, step 900/ 928, loss = 0.3696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:12<01:10, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 / 10, step 100/ 928, loss = 0.3408\n",
      "epoch 6 / 10, step 200/ 928, loss = 0.3578\n",
      "epoch 6 / 10, step 300/ 928, loss = 0.3489\n",
      "epoch 6 / 10, step 400/ 928, loss = 0.3502\n",
      "epoch 6 / 10, step 500/ 928, loss = 0.3562\n",
      "epoch 6 / 10, step 600/ 928, loss = 0.3526\n",
      "epoch 6 / 10, step 700/ 928, loss = 0.3548\n",
      "epoch 6 / 10, step 800/ 928, loss = 0.3362\n",
      "epoch 6 / 10, step 900/ 928, loss = 0.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:25<00:55, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 / 10, step 100/ 928, loss = 0.3345\n",
      "epoch 7 / 10, step 200/ 928, loss = 0.3475\n",
      "epoch 7 / 10, step 300/ 928, loss = 0.3459\n",
      "epoch 7 / 10, step 400/ 928, loss = 0.3371\n",
      "epoch 7 / 10, step 500/ 928, loss = 0.3699\n",
      "epoch 7 / 10, step 600/ 928, loss = 0.3448\n",
      "epoch 7 / 10, step 700/ 928, loss = 0.3670\n",
      "epoch 7 / 10, step 800/ 928, loss = 0.3392\n",
      "epoch 7 / 10, step 900/ 928, loss = 0.3247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:48<00:50, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 / 10, step 100/ 928, loss = 0.3397\n",
      "epoch 8 / 10, step 200/ 928, loss = 0.3338\n",
      "epoch 8 / 10, step 300/ 928, loss = 0.3469\n",
      "epoch 8 / 10, step 400/ 928, loss = 0.3254\n",
      "epoch 8 / 10, step 500/ 928, loss = 0.3426\n",
      "epoch 8 / 10, step 600/ 928, loss = 0.3280\n",
      "epoch 8 / 10, step 700/ 928, loss = 0.3201\n",
      "epoch 8 / 10, step 800/ 928, loss = 0.3302\n",
      "epoch 8 / 10, step 900/ 928, loss = 0.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:09<00:36, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 / 10, step 100/ 928, loss = 0.3281\n",
      "epoch 9 / 10, step 200/ 928, loss = 0.3398\n",
      "epoch 9 / 10, step 300/ 928, loss = 0.3156\n",
      "epoch 9 / 10, step 400/ 928, loss = 0.3266\n",
      "epoch 9 / 10, step 500/ 928, loss = 0.3263\n",
      "epoch 9 / 10, step 600/ 928, loss = 0.3322\n",
      "epoch 9 / 10, step 700/ 928, loss = 0.3119\n",
      "epoch 9 / 10, step 800/ 928, loss = 0.3082\n",
      "epoch 9 / 10, step 900/ 928, loss = 0.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:27<00:17, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 / 10, step 100/ 928, loss = 0.3067\n",
      "epoch 10 / 10, step 200/ 928, loss = 0.3115\n",
      "epoch 10 / 10, step 300/ 928, loss = 0.3196\n",
      "epoch 10 / 10, step 400/ 928, loss = 0.3165\n",
      "epoch 10 / 10, step 500/ 928, loss = 0.3151\n",
      "epoch 10 / 10, step 600/ 928, loss = 0.3105\n",
      "epoch 10 / 10, step 700/ 928, loss = 0.3082\n",
      "epoch 10 / 10, step 800/ 928, loss = 0.3229\n",
      "epoch 10 / 10, step 900/ 928, loss = 0.3081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:45<00:00, 16.55s/it]\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "#trainin loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        x = x.view(x.shape[0], 1)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        #forward\n",
    "        \n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        running_correct += (predicted ==y).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch +1} / {num_epochs}, step {i + 1}/ {n_total_steps}, loss = {loss.item():.4f}')\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('accuracy', running_correct / batch_size / 100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2b22cb1b-b2a0-42f4-9b52-4e23746ab15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_753641/201484662.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.37919978442537\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_sample = 0\n",
    "    for x, y in test_loader:\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        x = x.view(x.shape[0], 1).to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x)\n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_sample += y.shape[0]\n",
    "        n_correct += (predictions == y).sum().item()\n",
    "        \n",
    "acc = 100.0 * n_correct / n_sample\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "13c502a4-155c-4748-a6e4-108eb94cb32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir './runs/classification_all/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
